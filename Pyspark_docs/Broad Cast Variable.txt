PySpark Broadcast Variables:

In PySpark RDD and DataFrame, Broadcast variables are read-only shared variables that are cached and available
 
on all nodes in a cluster in-order to access or use by the tasks. 

Instead of sending this data along with every task, PySpark distributes broadcast variables to the workers 

using efficient broadcast algorithms to reduce communication costs.

Use case:

Let me explain with an example when to use broadcast variables, assume you are getting a two-letter country state code

 in a file and you wanted to transform it to full state name, (for example CA to California, NY to New York e.t.c) 

by doing a lookup to reference mapping.

 In some instances, this data could be large and you may have many such lookups (like zip code e.t.c).


How to create Broadcast variable:

The PySpark Broadcast is created using the broadcast(v) method of the SparkContext class.

This method takes the argument v that you want to broadcast.

import pyspark

from pyspark.sql import SparkSession

spark = SparkSession.builder.appName('BroadcastExample').getOrCreate()

states = {"NY":"New York", "CA":"California", "FL":"Florida"}

broadcastStates = spark.sparkContext.broadcast(states)


data = [("James","Smith","USA","CA"),
    ("Michael","Rose","USA","NY"),
    ("Robert","Williams","USA","CA"),
    ("Maria","Jones","USA","FL")
  ]

rdd = spark.sparkContext.parallelize(data)

def state_convert(code):
    return broadcastStates.value[code]

result = rdd.map(lambda x: (x[0],x[1],x[2],state_convert(x[3]))).collect()
print(result)

